## SIT796 Reinforcement Learning

## Pass Task 5.1: O learning and SARSA

## Overview

During week 5, you have learnt about some TD learning approaches.

- (a) In the Cliff Walking environment in the Week 5 workshop, SARSA seemed to learn safer policies compared to Q-learning. What is the reason for this?
- (b) What happens to their performances if you change both algorithms from a fixed epsilon policy to a decaying epsilon policy?

## Submission Details

Keep the answers short and to the point.

<!-- image -->